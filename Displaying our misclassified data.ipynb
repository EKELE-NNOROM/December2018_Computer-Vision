{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekele/.conda/envs/gpudeeplearning/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "# Training Parameters\n",
    "batch_size = 128\n",
    "epochs = 1\n",
    "\n",
    "#img_rows = x_train.shape[0]\n",
    "#img_cols = x_train.shape[0]\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Classes: 10\n"
     ]
    }
   ],
   "source": [
    "img_rows = x_train[0].shape[0]\n",
    "img_cols = x_train[1].shape[0]\n",
    "\n",
    "#reshaping to 4 dimensions for keras\n",
    "x_train = x_train.reshape(x_train.shape[0],img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "# shape of a single image\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalize our data by changing the range from (0 to 255) to (0 to 1)\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Converting to categorical data\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "# Let's count the number columns in our hot encoded matrix \n",
    "print (\"Number of Classes: \" + str(y_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_test.shape[1]\n",
    "x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = y_test.shape[1]\n",
    "num_pixels = x_train.shape[1] * x_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               4718720   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 4,738,826\n",
      "Trainable params: 4,738,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s 371us/step - loss: 0.2166 - acc: 0.9344 - val_loss: 0.0524 - val_acc: 0.9832\n",
      "Test loss: 0.05237158676437102\n",
      "Test accuracy 0.9832\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = keras.optimizers.Adam(),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "print (model.summary())\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serializing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"MNIST_history.pickle\",\"wb\")\n",
    "pickle.dump(history.history, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading saved history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [0.045635181629657746], 'acc': [0.9402333333651225], 'loss': [0.1997614995956421], 'val_acc': [0.9854]}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_in = open(\"MNIST_history.pickle\", \"rb\")\n",
    "saved_history = pickle.load(pickle_in)\n",
    "print(saved_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying confusion matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99       980\n",
      "          1       0.99      0.99      0.99      1135\n",
      "          2       0.98      0.98      0.98      1032\n",
      "          3       0.98      0.99      0.98      1010\n",
      "          4       0.99      0.98      0.99       982\n",
      "          5       0.97      0.99      0.98       892\n",
      "          6       0.99      0.98      0.99       958\n",
      "          7       0.99      0.98      0.98      1028\n",
      "          8       0.99      0.97      0.98       974\n",
      "          9       0.98      0.97      0.98      1009\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10000\n",
      "\n",
      "[[ 968    0    5    0    0    1    3    1    2    0]\n",
      " [   0 1127    2    1    0    2    1    1    1    0]\n",
      " [   0    4 1015    6    0    0    0    6    1    0]\n",
      " [   0    0    1 1003    0    4    0    1    1    0]\n",
      " [   0    0    1    0  966    0    5    0    2    8]\n",
      " [   0    0    0    5    0  886    1    0    0    0]\n",
      " [   7    2    0    1    2    6  940    0    0    0]\n",
      " [   1    2   11    4    0    0    0 1004    2    4]\n",
      " [   4    0    4    5    3    7    0    2  940    9]\n",
      " [   2    4    1    2    6    8    0    3    0  983]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "y_pred = model.predict_classes(x_test)\n",
    "print(classification_report(np.argmax(y_test,axis=1), y_pred))\n",
    "print(confusion_matrix(np.argmax(y_test,axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Displaying misclassified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test)  = mnist.load_data()\n",
    "result = np.absolute(y_test - y_pred)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of misclassified data are: \n",
      "\n",
      "(array([ 115,  247,  259,  321,  359,  445,  582,  619,  684,  691,  716,\n",
      "        717,  740,  846,  883,  924,  947,  965, 1014, 1039, 1112, 1182,\n",
      "       1202, 1226, 1232, 1247, 1260, 1319, 1326, 1364, 1393, 1500, 1522,\n",
      "       1527, 1530, 1549, 1553, 1621, 1681, 1709, 1717, 1722, 1754, 1878,\n",
      "       1901, 1903, 2016, 2035, 2043, 2053, 2098, 2118, 2130, 2135, 2182,\n",
      "       2189, 2293, 2329, 2387, 2406, 2422, 2447, 2454, 2597, 2607, 2654,\n",
      "       2896, 2927, 2939, 2953, 2995, 3012, 3030, 3062, 3073, 3289, 3330,\n",
      "       3503, 3520, 3559, 3597, 3674, 3718, 3727, 3751, 3757, 3767, 3780,\n",
      "       3808, 3811, 3850, 3853, 3906, 3941, 4007, 4065, 4075, 4176, 4199,\n",
      "       4205, 4224, 4238, 4248, 4360, 4497, 4511, 4536, 4571, 4575, 4601,\n",
      "       4639, 4671, 4740, 4761, 4807, 4874, 4956, 4978, 5140, 5331, 5634,\n",
      "       5642, 5887, 5937, 5955, 6071, 6091, 6166, 6505, 6555, 6560, 6576,\n",
      "       6597, 6603, 6625, 6651, 6755, 7121, 7216, 7434, 8059, 8069, 8094,\n",
      "       8273, 8278, 8325, 8382, 8408, 8527, 9009, 9015, 9019, 9024, 9280,\n",
      "       9634, 9642, 9664, 9679, 9692, 9729, 9755, 9768, 9792, 9811, 9839,\n",
      "       9856, 9888, 9892]),)\n"
     ]
    }
   ],
   "source": [
    "result_indices = np.nonzero(result > 0) # meaning misclassified\n",
    "result_indices\n",
    "print(\"Indices of misclassified data are: \\n\\n\" + str(result_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_indices[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function resize:\n",
      "\n",
      "resize(...)\n",
      "    resize(src, dsize[, dst[, fx[, fy[, interpolation]]]]) -> dst\n",
      "    .   @brief Resizes an image.\n",
      "    .   \n",
      "    .   The function resize resizes the image src down to or up to the specified size. Note that the\n",
      "    .   initial dst type or size are not taken into account. Instead, the size and type are derived from\n",
      "    .   the `src`,`dsize`,`fx`, and `fy`. If you want to resize src so that it fits the pre-created dst,\n",
      "    .   you may call the function as follows:\n",
      "    .   @code\n",
      "    .   // explicitly specify dsize=dst.size(); fx and fy will be computed from that.\n",
      "    .   resize(src, dst, dst.size(), 0, 0, interpolation);\n",
      "    .   @endcode\n",
      "    .   If you want to decimate the image by factor of 2 in each direction, you can call the function this\n",
      "    .   way:\n",
      "    .   @code\n",
      "    .   // specify fx and fy and let the function compute the destination image size.\n",
      "    .   resize(src, dst, Size(), 0.5, 0.5, interpolation);\n",
      "    .   @endcode\n",
      "    .   To shrink an image, it will generally look best with cv::INTER_AREA interpolation, whereas to\n",
      "    .   enlarge an image, it will generally look best with cv::INTER_CUBIC (slow) or cv::INTER_LINEAR\n",
      "    .   (faster but still looks OK).\n",
      "    .   \n",
      "    .   @param src input image.\n",
      "    .   @param dst output image; it has the size dsize (when it is non-zero) or the size computed from\n",
      "    .   src.size(), fx, and fy; the type of dst is the same as of src.\n",
      "    .   @param dsize output image size; if it equals zero, it is computed as:\n",
      "    .   \\f[\\texttt{dsize = Size(round(fx*src.cols), round(fy*src.rows))}\\f]\n",
      "    .   Either dsize or both fx and fy must be non-zero.\n",
      "    .   @param fx scale factor along the horizontal axis; when it equals 0, it is computed as\n",
      "    .   \\f[\\texttt{(double)dsize.width/src.cols}\\f]\n",
      "    .   @param fy scale factor along the vertical axis; when it equals 0, it is computed as\n",
      "    .   \\f[\\texttt{(double)dsize.height/src.rows}\\f]\n",
      "    .   @param interpolation interpolation method, see cv::InterpolationFlags\n",
      "    .   \n",
      "    .   @sa  warpAffine, warpPerspective, remap\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv2.resize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying the misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def draw_test(name, pred, input_im, true_label):\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(input_im, 0, 0, 0, imageL.shape[0]*2, cv2.BORDER_CONSTANT, value=BLACK)\n",
    "    expanded_image = cv2.cvtColor(expanded_image, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.putText(expanded_image, str(pred), (152, 70), cv2.FONT_HERSHEY_COMPLEX_SMALL, 4, (0,255,0), 2, cv2.LINE_AA)\n",
    "    cv2.putText(expanded_image, str(true_label), (250, 70), cv2.FONT_HERSHEY_COMPLEX_SMALL, 4, (0,0,255), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "    \n",
    "for i in range(0,10):\n",
    "    \n",
    "    input_im = x_test[result_indices[0][i]]\n",
    "    imageL = cv2.resize(input_im, None, fx=4, fy=4, interpolation=cv2.INTER_CUBIC)\n",
    "    input_im = input_im.reshape(1,28,28,1)\n",
    "    \n",
    "    res = str(model.predict_classes(input_im, 1, verbose = 0)[0])\n",
    "    draw_test(\"Prediction\", res, imageL, y_test[result_indices[0][i]])\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DATASCIENCE",
   "language": "python",
   "name": "datascience-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
